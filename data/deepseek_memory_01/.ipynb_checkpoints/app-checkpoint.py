# app.py

import gradio as gr
from langchain_community.embeddings import HuggingFaceEmbeddings

# å¯¼å…¥æˆ‘ä»¬çš„é…ç½®å’Œæ ¸å¿ƒé€»è¾‘
import config
from core_logic import build_knowledge_base, load_vector_db, answer_question, extract_and_save_memory

# --- 1. å…¨å±€å¯¹è±¡åŠ è½½ (ç¨‹åºå¯åŠ¨æ—¶æ‰§è¡Œä¸€æ¬¡) ---
print("[ç³»ç»Ÿå¯åŠ¨] æ­£åœ¨åˆå§‹åŒ–...")
build_knowledge_base()
with open(config.MEMORY_BANK_FILE, "r", encoding="utf-8") as f:
    known_memories = set(line.strip() for line in f if line.strip())

print("[ç³»ç»Ÿå¯åŠ¨] æ­£åœ¨åŠ è½½å‘é‡åŒ–æ¨¡å‹...")
embeddings = HuggingFaceEmbeddings(model_name=config.EMBEDDING_MODEL_NAME, model_kwargs={'device': 'cuda'})
db = load_vector_db(embeddings)
print("[ç³»ç»Ÿå¯åŠ¨] åˆå§‹åŒ–å®Œæˆï¼Gradioç•Œé¢å³å°†å¯åŠ¨ã€‚")


# --- 2. Gradio æ ¸å¿ƒé€»è¾‘ ---
def chat_response(message, chat_history):
    global db, known_memories, embeddings # å£°æ˜æˆ‘ä»¬éœ€è¦ä¿®æ”¹å…¨å±€çš„dbå’Œknown_memories
    
    conversation_history = []
    for user_msg, assistant_msg in chat_history:
        conversation_history.append({"role": "user", "content": user_msg})
        conversation_history.append({"role": "assistant", "content": assistant_msg})
    
    final_answer = answer_question(message, db, conversation_history)
    
    current_turn = {"user": message, "assistant": final_answer}
    if extract_and_save_memory(current_turn, known_memories):
        print("[Gradioåå°ï¼šæ£€æµ‹åˆ°è®°å¿†æ›´æ–°ï¼Œæ­£åœ¨é‡å»ºçŸ¥è¯†åº“...]")
        build_knowledge_base(force_rebuild=True)
        db = load_vector_db(embeddings) # é‡æ–°åŠ è½½æ›´æ–°åçš„æ•°æ®åº“
        print("[Gradioåå°ï¼šçŸ¥è¯†åº“é‡å»ºå®Œæˆï¼]")
        
    return final_answer

# --- 3. Gradio ç•Œé¢å®šä¹‰ ---
with gr.Blocks(theme=gr.themes.Soft(), title="RAG-Bot with Memory") as demo:
    gr.Markdown("# ğŸ§  å¸¦è®°å¿†çš„AIèŠå¤©ä¼™ä¼´")
    gr.Markdown("è¿™æ˜¯ä¸€ä¸ªç»“åˆäº†`RAG`ã€`é•¿æœŸè®°å¿†`å’Œ`çŸ­æœŸä¸Šä¸‹æ–‡`çš„AIèŠå¤©æœºå™¨äººDemoã€‚")
    
    chatbot = gr.Chatbot(
        label="èŠå¤©çª—å£",
        bubble_full_width=False,
        avatar_images=(None, "https://api.deepseek.com/deepseek.png"),
        height=600
    )
    
    with gr.Row():
        txt = gr.Textbox(show_label=False, placeholder="ä½ å¥½ï¼Œå¯ä»¥é—®æˆ‘ä»»ä½•é—®é¢˜...", lines=2, scale=4)
        submit_btn = gr.Button("å‘é€", variant="primary", scale=1)

    def respond(message, chat_history):
        bot_message = chat_response(message, chat_history)
        chat_history.append((message, bot_message))
        return "", chat_history

    submit_btn.click(respond, [txt, chatbot], [txt, chatbot])
    txt.submit(respond, [txt, chatbot], [txt, chatbot])

# --- 4. å¯åŠ¨GradioæœåŠ¡å™¨ ---
demo.launch(server_name="0.0.0.0")
